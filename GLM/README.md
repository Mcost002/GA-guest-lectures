# GA Guest Lecture on GLMs
The gracious people at General Assembly allowed me to give a guest lecture on a topic I am quite partial to: generalized linear models (GLMs).

### Data
Much of the data used here come from UCLA's IDRE tutorial modules.  I claim no rights to owning them.  I make no profit from using this data. The rest of the data is open source.  I used the famous `iris` data, as well as the ggplot2-included `diamonds` data.

### Notebooks
The lecture features intermittent code-a-longs. The `python-notebooks` directory contains Jupyter notebooks for the accompanying Python code. Feel free to clone this repository down and try the code out yourself!

### R Code
I believe it is important to be language-agnostic. Since R is my native tongue, I have also replicated all of the Python code in the `python-notebooks` folder into R for reference.  This can be found in the `R-notebooks` folder.  The 03 file in the `R-notebooks` folder contains an example of cumulative logistic regression - something not easily implemented in Python.

### Presentation
I am still considering whether or not I want to upload the full presentation.  I am leaning towards _no_, but feel free to contact me and ask anyway!

However, here is a list of topics I cover in the presentation:
* Recap OLS
* Recap logistic regression
* Discuss the general form of a GLM
* Discuss some common GLMs and their applications
* A brief interlude on model inference
* GLMs for classification
	* Logistic regression for classification
	* Multinomial regression for classification
	* Cumulative logit regression for classification
* GLM Pot Pourri
